{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4bf8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"flwr[simulation]\" \"flwr-datasets[vision]\" torch torchvision scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f28ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/.local/share/virtualenvs/ai.llm_prompting-rP8wfVkF/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-04 12:58:31,563\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.20.0 / PyTorch 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fed33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(partition_id: int, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396f6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerNumPyClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11a36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyclient_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerNumPyClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "numpyclient = ClientApp(client_fn=numpyclient_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b006161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(config=config)\n",
    "\n",
    "\n",
    "# Create ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eaaf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 8] get_parameters\n",
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m Epoch 1: train loss 0.06559710204601288, accuracy 0.214\n",
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20871)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m [Client 7] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20871)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m Epoch 1: train loss 0.06613316386938095, accuracy 0.21225\n",
      "\u001b[36m(ClientAppActor pid=20869)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m Epoch 1: train loss 0.06529438495635986, accuracy 0.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m Epoch 1: train loss 0.06570418179035187, accuracy 0.235\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m Epoch 1: train loss 0.05954650789499283, accuracy 0.29925\n",
      "\u001b[36m(ClientAppActor pid=20871)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m Epoch 1: train loss 0.05962961167097092, accuracy 0.29525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m Epoch 1: train loss 0.05954241007566452, accuracy 0.30375\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20868)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20874)\u001b[0m Epoch 1: train loss 0.05907357111573219, accuracy 0.31725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20871)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m Epoch 1: train loss 0.05596117302775383, accuracy 0.3385\n",
      "\u001b[36m(ClientAppActor pid=20871)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20867)\u001b[0m Epoch 1: train loss 0.054733727127313614, accuracy 0.35125\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=20872)\u001b[0m Epoch 1: train loss 0.05522831901907921, accuracy 0.35925\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20869)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\n",
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m Retrying in 8s [Retry 5/5].\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 166.71s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06395405081510544\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.05688847650289536\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.053622226190567016\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20873)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
    "\n",
    "NUM_PARTITIONS = 10\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=numpyclient,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7e7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import (\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Status,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "\n",
    "\n",
    "class FlowerClient(Client):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "\n",
    "        # Get parameters as a list of NumPy ndarray's\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters,\n",
    "        )\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        # Update local model, train, get updated parameters\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader),\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(loss),\n",
    "            num_examples=len(self.valloader),\n",
    "            metrics={\"accuracy\": float(accuracy)},\n",
    "        )\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2d966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m [Client 5] get_parameters\n",
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m Epoch 1: train loss 0.06568188220262527, accuracy 0.222\n",
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m Epoch 1: train loss 0.06524818390607834, accuracy 0.22875\n",
      "\u001b[36m(ClientAppActor pid=28673)\u001b[0m [Client 7] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28673)\u001b[0m Epoch 1: train loss 0.06572027504444122, accuracy 0.19975\n",
      "\u001b[36m(ClientAppActor pid=28675)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28680)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28675)\u001b[0m Epoch 1: train loss 0.06601592898368835, accuracy 0.193\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28679)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28679)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Epoch 1: train loss 0.059571534395217896, accuracy 0.30075\n",
      "\u001b[36m(ClientAppActor pid=28675)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28679)\u001b[0m Epoch 1: train loss 0.05950388312339783, accuracy 0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Epoch 1: train loss 0.05947599560022354, accuracy 0.307\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=28675)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Retrying in 1s [Retry 1/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Retrying in 8s [Retry 5/5].\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Epoch 1: train loss 0.05889628455042839, accuracy 0.314\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m [Client 9] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28674)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=28676)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Epoch 1: train loss 0.055597271770238876, accuracy 0.34875\n",
      "\u001b[36m(ClientAppActor pid=28675)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m Epoch 1: train loss 0.05474460870027542, accuracy 0.36575\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28676)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=28676)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=28676)\u001b[0m Epoch 1: train loss 0.05476615950465202, accuracy 0.36275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 144.83s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06479371778964997\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.056666840946674346\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.05364905495643616\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28677)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f71e8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from flwr.common.typing import NDArray, NDArrays, Parameters\n",
    "\n",
    "\n",
    "def ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n",
    "    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n",
    "    tensors = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n",
    "    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n",
    "\n",
    "\n",
    "def sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
    "    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n",
    "    return [sparse_bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
    "\n",
    "\n",
    "def ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n",
    "    \"\"\"Serialize NumPy ndarray to bytes.\"\"\"\n",
    "    bytes_io = BytesIO()\n",
    "\n",
    "    if len(ndarray.shape) > 1:\n",
    "        # We convert our ndarray into a sparse matrix\n",
    "        ndarray = torch.tensor(ndarray).to_sparse_csr()\n",
    "\n",
    "        # And send it byutilizing the sparse matrix attributes\n",
    "        # WARNING: NEVER set allow_pickle to true.\n",
    "        # Reason: loading pickled data can execute arbitrary code\n",
    "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
    "        np.savez(\n",
    "            bytes_io,  # type: ignore\n",
    "            crow_indices=ndarray.crow_indices(),\n",
    "            col_indices=ndarray.col_indices(),\n",
    "            values=ndarray.values(),\n",
    "            allow_pickle=False,\n",
    "        )\n",
    "    else:\n",
    "        # WARNING: NEVER set allow_pickle to true.\n",
    "        # Reason: loading pickled data can execute arbitrary code\n",
    "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
    "        np.save(bytes_io, ndarray, allow_pickle=False)\n",
    "    return bytes_io.getvalue()\n",
    "\n",
    "\n",
    "def sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n",
    "    \"\"\"Deserialize NumPy ndarray from bytes.\"\"\"\n",
    "    bytes_io = BytesIO(tensor)\n",
    "    # WARNING: NEVER set allow_pickle to true.\n",
    "    # Reason: loading pickled data can execute arbitrary code\n",
    "    # Source: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n",
    "    loader = np.load(bytes_io, allow_pickle=False)  # type: ignore\n",
    "\n",
    "    if \"crow_indices\" in loader:\n",
    "        # We convert our sparse matrix back to a ndarray, using the attributes we sent\n",
    "        ndarray_deserialized = (\n",
    "            torch.sparse_csr_tensor(\n",
    "                crow_indices=loader[\"crow_indices\"],\n",
    "                col_indices=loader[\"col_indices\"],\n",
    "                values=loader[\"values\"],\n",
    "            )\n",
    "            .to_dense()\n",
    "            .numpy()\n",
    "        )\n",
    "    else:\n",
    "        ndarray_deserialized = loader\n",
    "    return cast(NDArray, ndarray_deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0fa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import (\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Status,\n",
    ")\n",
    "\n",
    "\n",
    "class FlowerClient(Client):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "\n",
    "        # Get parameters as a list of NumPy ndarray's\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object using our custom function\n",
    "        parameters = ndarrays_to_sparse_parameters(ndarrays)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters,\n",
    "        )\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        # Update local model, train, get updated parameters\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object using our custom function\n",
    "        parameters_updated = ndarrays_to_sparse_parameters(ndarrays_updated)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader),\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(loss),\n",
    "            num_examples=len(self.valloader),\n",
    "            metrics={\"accuracy\": float(accuracy)},\n",
    "        )\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443487d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msymbol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parameters\n\u001b[32m      4\u001b[39m parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'symbol'"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f732a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepatlas)",
   "language": "python",
   "name": "deepatlas-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
