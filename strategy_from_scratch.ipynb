{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee9b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: flwr[simulation]\n"
     ]
    }
   ],
   "source": [
    "# Build a strategy from scratch\n",
    "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a9a895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/.local/share/virtualenvs/ai.llm_prompting-rP8wfVkF/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-04 12:29:53,094\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.20.0 / PyTorch 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import Strategy\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fa4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24812162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines the client-side logic for federated learning using the Flower framework.\n",
    "# \n",
    "# 1. The `FlowerClient` class inherits from `NumPyClient` and implements the required methods for a federated client:\n",
    "#    - `__init__`: Initializes the client with its partition ID, neural network, and data loaders for training and validation.\n",
    "#    - `get_parameters`: Returns the current model parameters. This is called by the server to get the client's model weights.\n",
    "#    - `fit`: Receives global model parameters from the server, updates the local model, trains it for one epoch on the client's local data, and returns the updated parameters and the number of training examples.\n",
    "#    - `evaluate`: Receives global model parameters, updates the local model, evaluates it on the client's validation data, and returns the loss, number of validation examples, and accuracy.\n",
    "#\n",
    "# 2. The `client_fn` function is a factory that creates a new `FlowerClient` instance for each client process. It:\n",
    "#    - Instantiates a new model and moves it to the appropriate device (CPU or GPU).\n",
    "#    - Retrieves the partition ID and number of partitions from the context.\n",
    "#    - Loads the training and validation data for this client partition.\n",
    "#    - Returns the client as a Flower-compatible client object.\n",
    "#\n",
    "# 3. Finally, a `ClientApp` is created using the `client_fn`, which is the entry point for running the client in a federated learning experiment.\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d850653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m [Client 8] get_parameters\n",
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m Epoch 1: train loss 0.06604356318712234, accuracy 0.212\n",
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m Epoch 1: train loss 0.06568748503923416, accuracy 0.218\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m Epoch 1: train loss 0.06581880897283554, accuracy 0.20425\n",
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4048)\u001b[0m Epoch 1: train loss 0.06530498713254929, accuracy 0.224\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m Epoch 1: train loss 0.05664949491620064, accuracy 0.3255\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m Epoch 1: train loss 0.05793365463614464, accuracy 0.3225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4044)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4044)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4044)\u001b[0m Epoch 1: train loss 0.05727699398994446, accuracy 0.33125\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/uoft-cs/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/uoft-cs/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/dataset_infos.json\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/dataset_infos.json\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4044)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4044)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Epoch 1: train loss 0.05279345437884331, accuracy 0.37725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Retrying in 2s [Retry 2/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4041)\u001b[0m Epoch 1: train loss 0.05397529527544975, accuracy 0.355\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Retrying in 1s [Retry 1/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=4045)\u001b[0m Epoch 1: train loss 0.0542261116206646, accuracy 0.35625\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4046)\u001b[0m Epoch 1: train loss 0.053807150572538376, accuracy 0.36625\n",
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\n",
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4043)\u001b[0m Epoch 1: train loss 0.053080376237630844, accuracy 0.37225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 115.68s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06396813477277756\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.054952736127376556\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.052292625081539146\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=4047)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NUM_PARTITIONS = 10\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    # If no strategy is provided, by default, ServerAppComponents will use FedAvg\n",
    "    return ServerAppComponents(config=config)\n",
    "\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Specify the resources each of your clients need\n",
    "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bfd66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "class FedCustom(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        standard_config = {\"lr\": 0.001}\n",
    "        higher_lr_config = {\"lr\": 0.003}\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            if idx < half_clients:\n",
    "                fit_configurations.append((client, FitIns(parameters, standard_config)))\n",
    "            else:\n",
    "                fit_configurations.append(\n",
    "                    (client, FitIns(parameters, higher_lr_config))\n",
    "                )\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "\n",
    "        # Let's assume we won't perform the global model evaluation on the server side.\n",
    "        return None\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a03fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 7] get_parameters\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m Epoch 1: train loss 0.06429890543222427, accuracy 0.21975\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13234)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m Epoch 1: train loss 0.06471852213144302, accuracy 0.215\n",
      "\u001b[36m(ClientAppActor pid=13234)\u001b[0m Epoch 1: train loss 0.06481718271970749, accuracy 0.213\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m Epoch 1: train loss 0.0644933432340622, accuracy 0.2155\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13238)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13238)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Epoch 1: train loss 0.05834822356700897, accuracy 0.302\n",
      "\u001b[36m(ClientAppActor pid=13236)\u001b[0m Epoch 1: train loss 0.05672045424580574, accuracy 0.323\n",
      "\u001b[36m(ClientAppActor pid=13236)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Epoch 1: train loss 0.0578608475625515, accuracy 0.31775\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13236)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Retrying in 1s [Retry 1/5].\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13235)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13235)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13237)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13238)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13236)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13235)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=13239)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13239)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m Epoch 1: train loss 0.053540877997875214, accuracy 0.3645\n",
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13240)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m Epoch 1: train loss 0.05401288717985153, accuracy 0.3695\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13234)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 110.04s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06156734501123427\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.05566076983213425\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.052821533501148224\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13241)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedCustom(),  # <-- pass the new strategy here\n",
    "    )\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b873ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 7] get_parameters\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m Epoch 1: train loss 0.06465314328670502, accuracy 0.2225\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14901)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m Epoch 1: train loss 0.06467147171497345, accuracy 0.22175\n",
      "\u001b[36m(ClientAppActor pid=14901)\u001b[0m Epoch 1: train loss 0.06458563357591629, accuracy 0.23175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m Epoch 1: train loss 0.06452812254428864, accuracy 0.23975\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14895)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14899)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Epoch 1: train loss 0.056990284472703934, accuracy 0.334\n",
      "\u001b[36m(ClientAppActor pid=14899)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m Epoch 1: train loss 0.05775522068142891, accuracy 0.31225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m Epoch 1: train loss 0.05718472972512245, accuracy 0.33375\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14896)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14898)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14895)\u001b[0m Epoch 1: train loss 0.05424690991640091, accuracy 0.35325\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Epoch 1: train loss 0.054067060351371765, accuracy 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 1s [Retry 1/5].\n",
      "\u001b[36m(ClientAppActor pid=14895)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/main/README.md\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 1s [Retry 1/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 8s [Retry 4/5].\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 8s [Retry 5/5].\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/cifar10.py\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m Retrying in 8s [Retry 5/5].\n",
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14897)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m Epoch 1: train loss 0.05395974963903427, accuracy 0.35525\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/cifar10/resolve/0b2714987fa478483af9968de7c934580d0bb9a2/.huggingface.yaml\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m Retrying in 4s [Retry 3/5].\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=14900)\u001b[0m Epoch 1: train loss 0.05394162982702255, accuracy 0.369\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 104.92s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.062151119661331175\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.05519558441638948\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.05231935760974884\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14902)\u001b[0m OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    }
   ],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedCustom(),  # <-- pass the new strategy here\n",
    "    )\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b1277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepatlas)",
   "language": "python",
   "name": "deepatlas-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
